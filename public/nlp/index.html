<!DOCTYPE html>
<html lang='en'><head>
  <meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='description' content='This page is primarily intended to document my notes about NLP, and be an aggregator of links that I&#39;d like to remember.
My Blog Posts  CNNs for NLP  Useful External Links  indicnlp and inltk CS224n Deep Learning for NLP by Christopher Manning - Currently going through this, really amazing course, enjoying learning some of the math going on behind the scene Distill&#39;s post on Memorization in RNNs and LSTMs, their post on Attention - Distill is indubitably the gold standard in ml explanations today.'>
<meta name='theme-color' content='#ffcd00'>

<meta property='og:title' content='NLP • Perpetual White Belt'>
<meta property='og:description' content='This page is primarily intended to document my notes about NLP, and be an aggregator of links that I&#39;d like to remember.
My Blog Posts  CNNs for NLP  Useful External Links  indicnlp and inltk CS224n Deep Learning for NLP by Christopher Manning - Currently going through this, really amazing course, enjoying learning some of the math going on behind the scene Distill&#39;s post on Memorization in RNNs and LSTMs, their post on Attention - Distill is indubitably the gold standard in ml explanations today.'>
<meta property='og:url' content='https://www.calmdownkarm.com/nlp/'>
<meta property='og:site_name' content='Perpetual White Belt'>
<meta property='og:type' content='article'><meta property='article:section' content='page'><meta property='article:published_time' content='2017-09-28T08:00:00&#43;06:00'/><meta property='article:modified_time' content='2017-09-28T08:00:00&#43;06:00'/><meta name='twitter:card' content='summary'>

<meta name="generator" content="Hugo 0.61.0" />

  <title>NLP • Perpetual White Belt</title>
  <link rel='canonical' href='https://www.calmdownkarm.com/nlp/'>
  
  
  <link rel='icon' href='/images/something.ico'>
<link rel='stylesheet' href='/assets/css/main.6a060eb7.css'><link rel='stylesheet' href='/css/custom.css'><style>
:root{--color-accent:#ffcd00;}
</style>

  

</head>
<body class='page type-page'>

  <div class='site'><a class='screen-reader-text' href='#content'>Skip to Content</a><div class='main'><nav id='main-menu' class='menu main-menu' aria-label='Main Menu'>
  <div class='container'>
    
    <ul><li class='item'>
        <a href='/'>Home</a>
      </li><li class='item'>
        <a href='/technical/'>technical</a>
      </li><li class='item current'>
        <a aria-current='page' href='/nlp/'>NLP</a>
      </li><li class='item'>
        <a href='/personal/'>personal</a>
      </li></ul>
  </div>
</nav><div class='header-widgets'>
        <div class='container'></div>
      </div>

      <header id='header' class='header site-header'>
        <div class='container sep-after'>
          <div class='header-info'><p class='site-title title'>Perpetual White Belt</p><p class='desc site-desc'>Machine Learning, Data Visualization and Brazilian Jiu Jitsu</p>
          </div>
        </div>
      </header>

      <main id='content'>


<article lang='en' class='entry'>
  <header class='header entry-header'>
  <div class='container sep-after'>
    <div class='header-info'>
      <h1 class='title'>NLP</h1>
      

    </div>
    

  </div>
</header>

  
  

  <div class='container entry-content'>
  <p>This page is primarily intended to document my notes about NLP, and be an aggregator of links that I'd like to remember.</p>
<h2 id="my-blog-posts">My Blog Posts</h2>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<ul>
<li><a href="/technical/yoon-kim/">CNNs for NLP</a></li>
</ul>
<h2 id="useful-external-links">Useful External Links</h2>
<ul>
<li><a href="http://indicnlp.org/">indicnlp</a> and <a href="https://github.com/goru001/inltk">inltk</a></li>
<li><a href="http://cs224n.stanford.edu/">CS224n Deep Learning for NLP by Christopher Manning</a> - Currently going through this, really amazing course, enjoying learning some of the math going on behind the scene</li>
<li><a href="https://distill.pub/2019/memorization-in-rnns/">Distill's post on Memorization in RNNs and LSTMs</a>, their post on <a href="https://distill.pub/2016/augmented-rnns/">Attention</a> - Distill is indubitably the gold standard in ml explanations today.</li>
</ul>
<h2 id="external-blog-posts-and-seminal-papers-that-ive-read-and-found-useful">External Blog Posts and Seminal Papers that I've read and found useful.</h2>
<ul>
<li><a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/">WildML, on Yoon Kim's Paper on CNNs for NLP</a>
<ul>
<li>Similar to the convolutions in signal processing.</li>
<li>CNNS are layers of convolutions with some sort of activation function determining output between layers. Thus &lsquo;regions of input&rsquo; are connected to output neurons as opposed to individual neurons being connected to output neurons.</li>
<li>affine layers are fully connected layers (typical in feed forward networks)</li>
<li>sentences/words are converted to vectors that contain word embeddings - this is what word2vec and GLOVE do. You could also potentially have a 1 hot encoded vector that indexes a word in a dictionary of some sort.</li>
<li>Thus a 10 word sentence using 100 dimensional vectors forms an 10X100 Matrix as the input.</li>
<li>Typical filters in CNNS for NLP will have row sized windows so entire words are examined at a time.</li>
<li>Sliding windows over 2-5 words at a time is typical.</li>
<li>Stride Size- amount of overlap between subsequent sliding windows, literature typically uses 1. Larger stride sizes will create heirarchial/tree like structures.</li>
<li>Wide/Narrow Convolution - whether zero padding is used for the edge inputs of the matrix.</li>
<li>Pooling layers - example 1 max pooling - the output of the filter can be represented by some subsample of the filter output. 1 max pooling reduces it to the highest single value in the filter. Pooling provides a fixed size output layer and reduces dimensionality. In images helps with invariance due to pixel shifts.</li>
<li>Input channels for images this is usually RGB/opacity. In text, it's often n-gram layers so 3,5,7 etc is pretty normal.</li>
</ul>
</li>
</ul>

</div>

  

</article>




      </main>

      <footer id='footer' class='footer'>
        <div class='container sep-before'><section class='widget widget-social_menu sep-after'><nav aria-label='Social Menu'>
    <ul><li>
        <a href='https://github.com/calmdownkarm' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Github account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
  
</svg>
</a>
      </li><li>
        <a href='https://twitter.com/karmanya' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Twitter account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"/>
  
</svg>
</a>
      </li><li>
        <a href='mailto:karmanyaaggarwal@gmail.com' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Contact via Email</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
  <polyline points="22,6 12,13 2,6"/>
  
</svg>
</a>
      </li><li>
        <a href='https://linkedin.com/in/calmdownkarm' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Linkedin account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"/>
  <rect x="2" y="9" width="4" height="12"/>
  <circle cx="4" cy="4" r="2"/>
  
</svg>
</a>
      </li><li>
        <a href='https://scholar.google.com/citations?user=A0d2Ji8AAAAJ' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Google_scholar account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M21.328 2.002v9.2M8.695 7.85c.014-.787-.11-2.236.28-2.89.623-1.045.856-1.39 1.797-1.989 1.953-.988 4.296.692 4.296.692.803.564 1.672 2.1 1.672 2.1l1.368-1.824-5.444-1.754-3.515 1.34L6.08 7.681m9.109 3.42s.65-.633 1.168-1.085c.461-.402.516-.714.6-.914.18-.426.268-.909.268-1.446 0-.7-.131-1.274-.388-1.735-.031-.053 0 0-.097-.157l4.588-3.762H10.32L3.672 7.85l5.023-.024c.23 1.237.619 1.575 1.019 2.222.744.719 1.13 1.194 2.215 1.194.254 0 2.6-.057 2.842-.09 0 0 .546 1.199-.133 1.71-.41.31.576 1.304.576 1.304s-5.577.831-6.523 1.427a4.13 4.13 0 0 0-1.306 1.277 3.034 3.034 0 0 0-.493 1.665c0 .502.106.955.32 1.357.214.403.493.733.84.99.345.258.744.473 1.194.649.45.174.896.297 1.342.367a8.348 8.348 0 0 0 3.41-.166 7.754 7.754 0 0 0 1.964-.807 4.28 4.28 0 0 0 1.49-1.443c.38-.609.57-1.292.57-2.049 0-.574-.116-1.096-.347-1.57a3.755 3.755 0 0 0-.847-1.164c-.335-.302-2.19-1.837-2.19-1.837"/>
  
</svg>
</a>
      </li></ul>
  </nav>
</section><div class='copyright'>
  <p>Minimo Theme &copy; 2017-2019 MunifTanjim </p>
</div>

        </div>
      </footer>

    </div>
  </div><script>window.__assets_js_src="/assets/js/"</script>

<script src='/assets/js/main.67d669ac.js'></script><script src='/js/custom.js'></script>

</body>

</html>

