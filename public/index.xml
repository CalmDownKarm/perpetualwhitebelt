<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Perpetual White Belt</title>
    <link>https://www.calmdownkarm.com/</link>
    <description>Recent content in Home on Perpetual White Belt</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 11 Jun 2019 09:00:00 +0630</lastBuildDate>
    
	<atom:link href="https://www.calmdownkarm.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>NLP</title>
      <link>https://www.calmdownkarm.com/nlp/</link>
      <pubDate>Thu, 28 Sep 2017 08:00:00 +0600</pubDate>
      
      <guid>https://www.calmdownkarm.com/nlp/</guid>
      <description>This page is primarily intended to document my notes about NLP, and be an aggregator of links that I&#39;d like to remember.
My Blog Posts  CNNs for NLP  Useful External Links  indicnlp and inltk CS224n Deep Learning for NLP by Christopher Manning - Currently going through this, really amazing course, enjoying learning some of the math going on behind the scene Distill&#39;s post on Memorization in RNNs and LSTMs, their post on Attention - Distill is indubitably the gold standard in ml explanations today.</description>
    </item>
    
    <item>
      <title>Lessons from a weekend of failing to handle a non-trivial amount of text</title>
      <link>https://www.calmdownkarm.com/technical/text-lessons/</link>
      <pubDate>Tue, 11 Jun 2019 09:00:00 +0630</pubDate>
      
      <guid>https://www.calmdownkarm.com/technical/text-lessons/</guid>
      <description>I&#39;ve been playing around with Common Crawl data lately - training some hindi language models. So I had about 25~ gigs of text to process, which I suppose is tiny compared to English Common Crawl (in the TB range); but it&#39;s right on the cusp of having to think a little bit on how to deal with it in the most efficient manner.
The server I was running this on had some 40 odd CPU cores and like 400 Gigs of RAM, so I wasn&#39;t terribly worried.</description>
    </item>
    
    <item>
      <title>Splat</title>
      <link>https://www.calmdownkarm.com/personal/splat/</link>
      <pubDate>Mon, 03 Jun 2019 09:00:00 +0600</pubDate>
      
      <guid>https://www.calmdownkarm.com/personal/splat/</guid>
      <description>Picture the idyllic, perfect day. Warm, but not overly so. Sunny, but not enough to be oppressive.
Breathe.
Picture the lush, beautiful green grass slowly rushing towards you as a stranger yells the phrase FLARE FLARE FLARE into your ear. In your mind, some remnant of a Michael Schumacher interview is telling you to relax your body because anything kept braced will break.You should be panicking, but strangely, you&#39;re extremely calm.</description>
    </item>
    
    <item>
      <title>Machine Learning is NOT Math</title>
      <link>https://www.calmdownkarm.com/technical/ml-not-math/</link>
      <pubDate>Fri, 31 May 2019 09:00:00 +0630</pubDate>
      
      <guid>https://www.calmdownkarm.com/technical/ml-not-math/</guid>
      <description>Machine Learning is firmly grounded in math - but why does it never feel like that day to day?. When I sit down to solve a math problem, not only is there a definitive answer, but more often than not there&#39;s an ideal way to approach the question. This ideal way never changes. When I sit down to solve an ML problem on the other hand, I always have to go through the same steps-</description>
    </item>
    
    <item>
      <title>डेटा डेजर्ट</title>
      <link>https://www.calmdownkarm.com/technical/data-deserts/</link>
      <pubDate>Tue, 16 Apr 2019 09:00:00 +0630</pubDate>
      
      <guid>https://www.calmdownkarm.com/technical/data-deserts/</guid>
      <description>The other day, I was helping out some people at my research lab write a couple of sentiment analysis classifiers for the Hindi Language and I was surprised to find that almost every famous English Language Model(Glove, FastText, Word2vec) has a Hindi equivalent that is very easy to find. I was even more surprised to find despite this, there is a dearth of well put together, annotated datasets for modern NLP Tasks.</description>
    </item>
    
    <item>
      <title>Migrations</title>
      <link>https://www.calmdownkarm.com/personal/migrations/</link>
      <pubDate>Mon, 11 Mar 2019 09:00:00 +0600</pubDate>
      
      <guid>https://www.calmdownkarm.com/personal/migrations/</guid>
      <description>For the second time in two years now, I&#39;ve decamped and moved cities. Unexpectedly, there&#39;s a fair amount of culture shock. In the past year I&#39;ve gotten accustomed to being in a very quiet city and Delhi is certainly not that. Plus I&#39;ve had relatives over, other relatives passing away and social obligations that I can&#39;t postpone, so things have been fairly busy; a far cry from how introverted I&#39;d become in Hyderabad.</description>
    </item>
    
    <item>
      <title>Lazy Callbacks</title>
      <link>https://www.calmdownkarm.com/personal/lazy-callbacks/</link>
      <pubDate>Sun, 30 Dec 2018 09:00:00 +0600</pubDate>
      
      <guid>https://www.calmdownkarm.com/personal/lazy-callbacks/</guid>
      <description>Around this time last year, I had a few goals in mind for this year. However, I didn&#39;t exactly write them down - and as most of my friends will attest, my memory isn&#39;t the best, so I&#39;m kinda winging it.
  Jiu Jitsu - My biggest goal at the start of the year, was to get all the weird shit with my head sorted out so I could go back to doing jiu jitsu.</description>
    </item>
    
    <item>
      <title>Healthy Dose of Skepticism with Machine Learning</title>
      <link>https://www.calmdownkarm.com/technical/skepticism/</link>
      <pubDate>Tue, 04 Dec 2018 09:00:00 +0630</pubDate>
      
      <guid>https://www.calmdownkarm.com/technical/skepticism/</guid>
      <description>This week, 2 small changes to the way I built two models resulted in an absurd boost of performance of both. To the extent where it doesn&#39;t even make sense for the models to be this good. The obvious conclusion then becomes that I&#39;ve made some mistake somewhere. Thing is, I have absolutely no idea where the mistake lies - but in the attempt to figure it out, I was forced to take a closer look at both the model and the data, aided by a healthy dose of skeptcisim towards what the models do and how good their performance can be.</description>
    </item>
    
    <item>
      <title>A twitter bot under 20 lines of code and 30 lines of configuration</title>
      <link>https://www.calmdownkarm.com/technical/twitterbot/</link>
      <pubDate>Tue, 16 Oct 2018 09:00:00 +0630</pubDate>
      
      <guid>https://www.calmdownkarm.com/technical/twitterbot/</guid>
      <description>A project underway at the lab in IIITDelhi that I&#39;m volunteering at involves collecting a decently large collection of tweets. The bot needs to run at regular intervals, hit the search API with a series of keywords and store the returned tweets. More than that, it needed to be written completely in python and fairly difficult for a bored undergrad to break. I chose Gramex - since I work for the company that builds it, and I hadn&#39;t had a chance to test our TwitterRESTHandler yet.</description>
    </item>
    
    <item>
      <title>SSH Configurations</title>
      <link>https://www.calmdownkarm.com/technical/ssh-config/</link>
      <pubDate>Sun, 16 Sep 2018 09:00:00 +0630</pubDate>
      
      <guid>https://www.calmdownkarm.com/technical/ssh-config/</guid>
      <description>I&#39;m spending most of this long discontinuous weekend to run through all the fast.ai notebooks - while I find this course really helped me get a theoretical understanding of what neural nets are and how they work, I find that it takes me an inordinate amount of time to produce actual code - probably due to the fact that I never wrote anything while doing the course.
So this time around, I&#39;m simply recreating each of the notebooks as quickly as I can, but ensuring that I&#39;m actually implementing everything myself as compared to just running cells in their notebooks</description>
    </item>
    
    <item>
      <title>Convolutional Neural Networks for Sentence Classification</title>
      <link>https://www.calmdownkarm.com/technical/yoon-kim/</link>
      <pubDate>Fri, 10 Aug 2018 09:00:00 +0630</pubDate>
      
      <guid>https://www.calmdownkarm.com/technical/yoon-kim/</guid>
      <description>This post is going to be a small repository of information about Yoon Kim&#39;s paper on using Convolutional Neural Networks for Sentence Classification.
  Arxiv Link
  Author&#39;s Github Link
  TODO: My pytorch implementation
  Yoon Kim and his team, talk about using Convolutional Neural Nets as a means for sentence classification - essentially, they create sentence vectors by taking word vectors and concatenating them together, then pass them through layers of convolutions or filters to create what they call a feature map, which is literally just a set of filter outputs.</description>
    </item>
    
    <item>
      <title>Change</title>
      <link>https://www.calmdownkarm.com/personal/change/</link>
      <pubDate>Sat, 12 May 2018 09:00:00 +0600</pubDate>
      
      <guid>https://www.calmdownkarm.com/personal/change/</guid>
      <description>Four years ago, I sat behind Engineering Hall on campus at the University of Illinois and the enormity of my fuck-up struck for the perhaps the first time. Over the course of a long year and a half I had made a series of bad decisions that ended up in my dropping out of one the best ranked engineering programs in the world, returning to India and starting all over.</description>
    </item>
    
    <item>
      <title>Comments Support</title>
      <link>https://www.calmdownkarm.com/personal/comments-support/</link>
      <pubDate>Thu, 29 Mar 2018 09:00:00 +0600</pubDate>
      
      <guid>https://www.calmdownkarm.com/personal/comments-support/</guid>
      <description>Minimo has support for comments baked into it.
Enable/Disable Comments Globally For enabling or disabling comments globally, check the following setting in your config.toml file:
[params.comments] enable = false  params.comments [Map]:  enable [Boolean]: Enable/Disable comments globally    For Specific Posts The global .Site.Params.comments.enable setting can be overridden for specific posts in their content&#39;s frontmatter with this option:
--- comments: true ---  comments [Boolean]: Enable/Disable comments for specific posts  Of course, you&#39;ll also need to setup a comment system ( Disqus or Staticman ).</description>
    </item>
    
  </channel>
</rss>